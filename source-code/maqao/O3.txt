Target processor is: 11th generation Intel Core processors based on Tiger Lake microarchitecture (x86_64 architecture).

[MAQAO] Info: No innermost loops in the function _Z5saxpyfRKSt6vectorIfSaIfEES3_RS1_.cold
Section 1: Function: saxpy(float, std::vector<float, std::allocator<float> > const&, std::vector<float, std::allocator<float> > const&, std::vector<float, std::allocator<float> >&)
====================================================================================================================================================================================

Code for this function has been compiled to run on any x86-64 processor (SSE2, 2004). It is not optimized for later processors (AVX etc.).
These loops are supposed to be defined in: /home/gjb/Projects/Code-optimization/source-code/maqao/saxpy.cpp

Section 1.1: Source loop ending at line 11
==========================================

Composition and unrolling
-------------------------
It is composed of the following loops [ID (first-last source line)]:
 - 2 (10-11)
 - 3 (11-11)
and is unrolled by 4 (including vectorization).

The following loops are considered as:
 - unrolled and/or vectorized main: 3
 - peel or tail: 2
The analysis will be displayed for the unrolled and/or vectorized loops: 3

Section 1.1.1: Binary (unrolled and/or vectorized) loop #3
==========================================================

The loop is defined in:
 - /home/gjb/Projects/Code-optimization/source-code/maqao/saxpy.cpp:11
 - /usr/include/c++/13/bits/stl_vector.h:989


It is main loop of related source loop which is unrolled by 4 (including vectorization).
8% of peak computational performance is used (5.71 out of 64.00 FLOP per cycle (GFLOPS @ 1GHz))

Vector unaligned load/store instructions
----------------------------------------
Detected 3 suboptimal vector unaligned load/store instructions.

 - MOVUPS: 3 occurrences

Workaround(s):
 - Recompile with march=tigerlake.
CQA target is Tiger_Lake_8d (11th generation Intel Core processors based on Tiger Lake microarchitecture) but specialization flags are -march=x86-64
 - Use vector aligned instructions:
  1) align your arrays on 64 bytes boundaries: replace { void *p = malloc (size); } with { void *p; posix_memalign (&p, 64, size); }.
  2) inform your compiler that your arrays are vector aligned: if array 'foo' is 64 bytes-aligned, define a pointer 'p_foo' as __builtin_assume_aligned (foo, 64) and use it instead of 'foo' in the loop.


Type of elements and instruction set
------------------------------------
2 SSE or AVX instructions are processing arithmetic or math operations on single precision FP elements in vector mode (four at a time).


Matching between your loop (in the source code) and the binary loop
-------------------------------------------------------------------
The binary loop is composed of 8 FP arithmetical operations:
 - 4: addition or subtraction
 - 4: multiply
The binary loop is loading 32 bytes (8 single precision FP elements).
The binary loop is storing 16 bytes (4 single precision FP elements).

Arithmetic intensity
--------------------
Arithmetic intensity is 0.17 FP operations per loaded or stored byte.

General properties
------------------
nb instructions    : 8
nb uops            : 7
loop length        : 28
used x86 registers : 5
used mmx registers : 0
used xmm registers : 3
used ymm registers : 0
used zmm registers : 0
nb stack references: 0
ADD-SUB / MUL ratio: 1.00


Front-end
---------
ASSUMED MACRO FUSION
FIT IN UOP CACHE
micro-operation queue: 1.40 cycles
front end            : 1.40 cycles


Back-end
--------
       | P0   | P1   | P2   | P3   | P4   | P5   | P6   | P7   | P8   | P9
----------------------------------------------------------------------------
uops   | 1.00 | 1.00 | 1.00 | 1.00 | 0.50 | 1.00 | 1.00 | 0.50 | 0.50 | 0.50
cycles | 1.00 | 1.00 | 1.00 | 1.00 | 0.50 | 1.00 | 1.00 | 0.50 | 0.50 | 0.50

Execution ports to units layout:
 - P0 (256 bits): VPU, BRU, ALU, DIV/SQRT
 - P1 (256 bits): ALU, VPU
 - P2 (512 bits): load
 - P3 (512 bits): load
 - P4 (256 bits): store data
 - P5 (512 bits): ALU, VPU
 - P6: ALU, BRU
 - P7: store address
 - P8: store address
 - P9 (256 bits): store data

Cycles executing div or sqrt instructions: NA
Longest recurrence chain latency (RecMII): 1.00


Cycles summary
--------------
Front-end : 1.40
Dispatch  : 1.00
Data deps.: 1.00
Overall L1: 1.40


Vectorization ratios
--------------------
all     : 100%
load    : 100%
store   : 100%
mul     : 100%
add-sub : 100%
fma     : NA (no fma vectorizable/vectorized instructions)
div/sqrt: NA (no div/sqrt vectorizable/vectorized instructions)
other   : NA (no other vectorizable/vectorized instructions)


Vector efficiency ratios
------------------------
all     : 25%
load    : 25%
store   : 25%
mul     : 25%
add-sub : 25%
fma     : NA (no fma vectorizable/vectorized instructions)
div/sqrt: NA (no div/sqrt vectorizable/vectorized instructions)
other   : NA (no other vectorizable/vectorized instructions)


Cycles and memory resources usage
---------------------------------
Assuming all data fit into the L1 cache, each iteration of the binary loop takes 1.40 cycles. At this rate:
 - 17% of peak load performance is reached (22.86 out of 128.00 bytes loaded per cycle (GB/s @ 1GHz))
 - 17% of peak store performance is reached (11.43 out of 64.00 bytes stored per cycle (GB/s @ 1GHz))


Front-end bottlenecks
---------------------
Performance is limited by instruction throughput (loading/decoding program instructions to execution core) (front-end is a bottleneck).

By removing all these bottlenecks, you can lower the cost of an iteration from 1.40 to 1.00 cycles (1.40x speedup).


ASM code
--------
In the binary file, the address of the loop is: 29d0

Instruction                                         | Nb FU | P0   | P1   | P2   | P3   | P4   | P5   | P6   | P7   | P8   | P9   | Latency | Recip. throughput | Vectorization
-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
MOVUPS (%R8,%RAX,1),%XMM1                           | 1     | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 0    | 0    | 3       | 0.50              | vect (25.0%)
MOVUPS (%RDI,%RAX,1),%XMM3                          | 1     | 0    | 0    | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 0    | 0    | 3       | 0.50              | vect (25.0%)
MULPS %XMM2,%XMM1                                   | 1     | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 4       | 0.50              | vect (25.0%)
ADDPS %XMM3,%XMM1                                   | 1     | 0.50 | 0.50 | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 4       | 0.50              | vect (25.0%)
MOVUPS %XMM1,(%RCX,%RAX,1)                          | 1     | 0    | 0    | 0    | 0    | 0.50 | 0    | 0    | 0.50 | 0.50 | 0.50 | 1       | 0.50              | vect (25.0%)
ADD $0x10,%RAX                                      | 1     | 0.25 | 0.25 | 0    | 0    | 0    | 0.25 | 0.25 | 0    | 0    | 0    | 1       | 0.25              | N/A
CMP %RSI,%RAX                                       | 1     | 0.25 | 0.25 | 0    | 0    | 0    | 0.25 | 0.25 | 0    | 0    | 0    | 1       | 0.25              | N/A
JNE 29d0 <_Z5saxpyfRKSt6vectorIfSaIfEES3_RS1_+0xa0> | 1     | 0.50 | 0    | 0    | 0    | 0    | 0    | 0.50 | 0    | 0    | 0    | 0       | 0.50-1            | N/A



All innermost loops were analyzed.

